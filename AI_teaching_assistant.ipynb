{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpjCbPiLDgoJ"
      },
      "source": [
        "**AI-Teaching Assistant - Project**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Luybu_MHDrXc"
      },
      "outputs": [],
      "source": [
        "import fitz  \n",
        "doc = fitz.open(\"Excerpts - Arendt - The Human Condition.pdf\")\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.create_documents([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_331868\\4184729053.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "texts = [doc.page_content for doc in docs]\n",
        "\n",
        "doc_embeddings = embeddings.embed_documents(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_331868\\3270450041.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  relevant_docs = retriever.get_relevant_documents(\"What is labor for Arendt?\")\n"
          ]
        }
      ],
      "source": [
        "retriever = db.as_retriever(search_type=\"similarity\", k=3)\n",
        "relevant_docs = retriever.get_relevant_documents(\"What is labor for Arendt?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 \n",
            " \n",
            "Excerpts – The Human Condition - Hannah Arendt (1958) \n",
            " \n",
            "The Fate of Our Times for Arendt \n",
            " \n",
            "Closer at hand and perhaps equally decisive is another no less threatening event. This is the \n",
            "advent of automation, which in a few decades probably will empty the factories and liberate \n",
            "mankind from its oldest and most natural burden, the burden of laboring and the bondage to \n",
            "necessity…The modern age has carried with it a theoretical glorification of labor and has\n",
            "\n",
            "through the interrelated faculties of action and speech, which produce meaningful stories as \n",
            "naturally as fabrication produces use objects. \n",
            " \n",
            "Arendt on how labor (not work or action) are the dominant activity in which human-beings \n",
            "participate in the modern world \n",
            " \n",
            "Among the outstanding characteristics of the modern age from its beginning to our own time we \n",
            "find the typical attitudes of homo faber: his instrumentalization of the world, his confidence in\n",
            "\n",
            "resulted in a factual transformation of the whole of society into a laboring society. The fulfilment \n",
            "of the wish, therefore, like the fulfilment of wishes in fairy tales, comes at a moment when it can \n",
            "only be self-defeating. It is a society of laborers which is about to be liberated from the fetters of \n",
            "labor, and this society does no longer know of those other higher and more meaningful activities \n",
            "for the sake of which this freedom would deserve to be won…Even presidents, kings, and prime\n",
            "\n",
            "The blessing of life as a whole, inherent in labor, can never be found in work and should not be \n",
            "mistaken for the inevitably brief spell of relief and joy which follows accomplishment and \n",
            "attends achievement. The blessing of labor is that effort and gratification follow each other as \n",
            "closely as producing and consuming the means of subsistence, so that happiness is a concomitant \n",
            "of the process itself, just as pleasure is a concomitant of the functioning of a healthy body…\n",
            "<InferenceClient(model='tiiuae/falcon-7b-instruct', timeout=None)>\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
        "query = \"What is labor for Arendt?\"\n",
        "\n",
        "context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "final_prompt = f\"\"\"Answer the question using the context below. If the answer is not in the context, say \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "client = InferenceClient(\n",
        "    provider=\"hf-inference\",\n",
        "    model= \"tiiuae/falcon-7b-instruct\",\n",
        "    token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        ")\n",
        "\n",
        "response = client.text_generation(\n",
        "    prompt=final_prompt,\n",
        "    max_new_tokens=200,\n",
        "    temperature=0.3,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
